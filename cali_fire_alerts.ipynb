{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffee/anaconda3/envs/wildfire/lib/python3.10/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'hms_fire2020.kml': 'Overlay' (default), 'Fire (Final)'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geo_df = gpd.read_file(\"data/hms_fire2020.kml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def parse_hms_fire_kml_to_geodf(path, max_points=None):\n",
    "    ns = \"{http://www.opengis.net/kml/2.2}\"\n",
    "    rows = []\n",
    "    count = 0\n",
    "\n",
    "    context = ET.iterparse(path, events=(\"end\",))\n",
    "\n",
    "    for event, elem in context:\n",
    "        # We only care about Placemark elements\n",
    "        if not elem.tag.endswith(\"Placemark\"):\n",
    "            continue\n",
    "\n",
    "        # <description> block\n",
    "        desc = elem.find(f\"{ns}description\")\n",
    "        if desc is None or desc.text is None:\n",
    "            elem.clear()\n",
    "            continue\n",
    "\n",
    "        desc_text = desc.text.replace(\"<br>\", \"\\n\")\n",
    "\n",
    "        meta = {}\n",
    "        for line in desc_text.split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                key, val = line.split(\":\", 1)\n",
    "                meta[key.strip()] = val.strip()\n",
    "\n",
    "        point = elem.find(f\".//{ns}Point\")\n",
    "        if point is None:\n",
    "            elem.clear()\n",
    "            continue\n",
    "\n",
    "        coords_tag = point.find(f\"{ns}coordinates\")\n",
    "        if coords_tag is None or coords_tag.text is None:\n",
    "            elem.clear()\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            lon_str, lat_str, *_ = coords_tag.text.strip().split(\",\")\n",
    "            lon = float(lon_str)\n",
    "            lat = float(lat_str)\n",
    "        except Exception:\n",
    "            elem.clear()\n",
    "            continue\n",
    "\n",
    "        meta[\"lon\"] = lon\n",
    "        meta[\"lat\"] = lat\n",
    "\n",
    "        rows.append(meta)\n",
    "        count += 1\n",
    "\n",
    "        # Optional: stop early for testing\n",
    "        if max_points is not None and count >= max_points:\n",
    "            break\n",
    "\n",
    "        # Free memory for processed element\n",
    "        elem.clear()\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    if \"FRP\" in df.columns:\n",
    "        df[\"FRP\"] = (\n",
    "            df[\"FRP\"]\n",
    "            .astype(str)\n",
    "            .str.replace(\"MW\", \"\", regex=False)\n",
    "            .replace(\"-999.000\", pd.NA)\n",
    "        )\n",
    "        df[\"FRP\"] = pd.to_numeric(df[\"FRP\"], errors=\"coerce\")\n",
    "\n",
    "    if \"YearDay\" in df.columns:\n",
    "        df[\"YearDay\"] = pd.to_numeric(df[\"YearDay\"], errors=\"coerce\")\n",
    "\n",
    "    # Build geometry\n",
    "    geometry = [Point(xy) for xy in zip(df[\"lon\"], df[\"lat\"])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2491671,\n",
       "            Lon        Lat  YearDay     Time  Satellite    Method Ecosystem  \\\n",
       " 0   -89.007000  43.250000  2020001  0001UTC  GOES-EAST  ANALYSIS        30   \n",
       " 1  -115.107000  32.665000  2020001  0020UTC  GOES-WEST  ANALYSIS        51   \n",
       " 2  -117.667000  47.512000  2020001  0106UTC  GOES-WEST  ANALYSIS        40   \n",
       " 3   -86.205000  32.640000  2020001  0120UTC    METOP-A  ANALYSIS        27   \n",
       " 4   -78.546000  35.440000  2020001  0120UTC    METOP-A  ANALYSIS        31   \n",
       " \n",
       "    FRP      lon     lat                 geometry  \n",
       " 0  NaN  -89.007  43.250    POINT (-89.007 43.25)  \n",
       " 1  NaN -115.107  32.665  POINT (-115.107 32.665)  \n",
       " 2  NaN -117.667  47.512  POINT (-117.667 47.512)  \n",
       " 3  NaN  -86.205  32.640    POINT (-86.205 32.64)  \n",
       " 4  NaN  -78.546  35.440    POINT (-78.546 35.44)  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire2020_gdf = parse_hms_fire_kml_to_geodf(\"data/hms_fire2020.kml\", max_points=None)\n",
    "len(fire2020_gdf), fire2020_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = gpd.read_file(\"data/cb_2018_us_state_500k/cb_2018_us_state_500k.shp\")\n",
    "ca = states[states[\"NAME\"] == \"California\"].to_crs(\"EPSG:4326\")\n",
    "\n",
    "ca_fire = gpd.sjoin(fire2020_gdf, ca, how=\"inner\", predicate=\"intersects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_hms_datetime(yd, time_str):\n",
    "    date = pd.to_datetime(str(yd), format=\"%Y%j\")\n",
    "\n",
    "    hhmm = time_str.replace(\"UTC\", \"\")\n",
    "    hour = int(hhmm[:2])\n",
    "    minute = int(hhmm[2:])\n",
    "\n",
    "    return date + pd.Timedelta(hours=hour, minutes=minute)\n",
    "\n",
    "ca_fire[\"timestamp\"] = ca_fire.apply(\n",
    "    lambda row: parse_hms_datetime(row[\"YearDay\"], row[\"Time\"]),\n",
    "    axis=1\n",
    ")\n",
    "ca_fire[\"lon_round\"] = ca_fire[\"lon\"].round(3)\n",
    "ca_fire[\"lat_round\"] = ca_fire[\"lat\"].round(3)\n",
    "ca_fire[\"pixel_id\"] = (ca_fire[\"lon_round\"].astype(str) + \"_\" + ca_fire[\"lat_round\"].astype(str))\n",
    "\n",
    "ca_fire = ca_fire.sort_values([\"pixel_id\", \"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "gap = pd.Timedelta(hours=2)\n",
    "\n",
    "ca_fire[\"prev_time\"] = ca_fire.groupby(\"pixel_id\")[\"timestamp\"].shift(1)\n",
    "ca_fire[\"gap\"] = ca_fire[\"timestamp\"] - ca_fire[\"prev_time\"]\n",
    "\n",
    "ca_fire[\"new_episode\"] = (ca_fire[\"gap\"] > gap) | ca_fire[\"gap\"].isna()\n",
    "\n",
    "ca_fire[\"episode_id\"] = ca_fire.groupby(\"pixel_id\")[\"new_episode\"].cumsum()\n",
    "\n",
    "episodes = (\n",
    "    ca_fire.groupby([\"pixel_id\", \"episode_id\"])\n",
    "    .agg(\n",
    "        lon=(\"lon_round\", \"first\"),\n",
    "        lat=(\"lat_round\", \"first\"),\n",
    "        start_time=(\"timestamp\", \"min\"),\n",
    "        end_time=(\"timestamp\", \"max\"),\n",
    "        n_detections=(\"timestamp\", \"count\"),\n",
    "        satellites=(\"Satellite\", lambda x: sorted(x.unique())),\n",
    "        ecosystems=(\"Ecosystem\", lambda x: sorted(x.unique())),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "episodes[\"geometry\"] = episodes.apply(\n",
    "    lambda r: Point(r[\"lon\"], r[\"lat\"]), axis=1\n",
    ")\n",
    "\n",
    "episodes_gdf = gpd.GeoDataFrame(episodes, geometry=\"geometry\", crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fire pixels: 482158\n",
      "Number of unique fire events: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>n_detections</th>\n",
       "      <th>satellites</th>\n",
       "      <th>ecosystems</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.141_34.281</td>\n",
       "      <td>1</td>\n",
       "      <td>-114.141</td>\n",
       "      <td>34.281</td>\n",
       "      <td>2020-02-18 08:20:00</td>\n",
       "      <td>2020-02-18 08:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[NOAA-20]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>POINT (-114.141 34.281)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.148_34.279</td>\n",
       "      <td>1</td>\n",
       "      <td>-114.148</td>\n",
       "      <td>34.279</td>\n",
       "      <td>2020-02-18 06:30:00</td>\n",
       "      <td>2020-02-18 06:36:00</td>\n",
       "      <td>2</td>\n",
       "      <td>[GOES-EAST]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>POINT (-114.148 34.279)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.14_34.279</td>\n",
       "      <td>1</td>\n",
       "      <td>-114.140</td>\n",
       "      <td>34.279</td>\n",
       "      <td>2020-02-18 10:00:00</td>\n",
       "      <td>2020-02-18 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[NOAA-20]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>POINT (-114.14 34.279)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.464_32.896</td>\n",
       "      <td>1</td>\n",
       "      <td>-114.464</td>\n",
       "      <td>32.896</td>\n",
       "      <td>2020-02-25 19:31:00</td>\n",
       "      <td>2020-02-25 19:31:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[GOES-EAST]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>POINT (-114.464 32.896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.486_32.914</td>\n",
       "      <td>1</td>\n",
       "      <td>-114.486</td>\n",
       "      <td>32.914</td>\n",
       "      <td>2020-02-23 19:44:00</td>\n",
       "      <td>2020-02-23 19:44:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[NOAA-20]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>POINT (-114.486 32.914)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pixel_id  episode_id      lon     lat          start_time  \\\n",
       "0  -114.141_34.281           1 -114.141  34.281 2020-02-18 08:20:00   \n",
       "1  -114.148_34.279           1 -114.148  34.279 2020-02-18 06:30:00   \n",
       "2   -114.14_34.279           1 -114.140  34.279 2020-02-18 10:00:00   \n",
       "3  -114.464_32.896           1 -114.464  32.896 2020-02-25 19:31:00   \n",
       "4  -114.486_32.914           1 -114.486  32.914 2020-02-23 19:44:00   \n",
       "\n",
       "             end_time  n_detections   satellites ecosystems  \\\n",
       "0 2020-02-18 08:20:00             1    [NOAA-20]       [51]   \n",
       "1 2020-02-18 06:36:00             2  [GOES-EAST]       [51]   \n",
       "2 2020-02-18 10:00:00             1    [NOAA-20]       [51]   \n",
       "3 2020-02-25 19:31:00             1  [GOES-EAST]       [51]   \n",
       "4 2020-02-23 19:44:00             1    [NOAA-20]       [51]   \n",
       "\n",
       "                  geometry  \n",
       "0  POINT (-114.141 34.281)  \n",
       "1  POINT (-114.148 34.279)  \n",
       "2   POINT (-114.14 34.279)  \n",
       "3  POINT (-114.464 32.896)  \n",
       "4  POINT (-114.486 32.914)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of fire pixels: {len(episodes_gdf)}\")\n",
    "\n",
    "num_unique_pixels = ca_fire[\"episode_id\"].nunique()\n",
    "print(f\"Number of unique fire events: {num_unique_pixels}\")\n",
    "\n",
    "episodes_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_hms_fire_kml_to_geodf(filepath):\n",
    "\n",
    "    ns = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    placemarks = root.findall(\".//kml:Placemark\", ns)\n",
    "\n",
    "    rows = []\n",
    "    for pm in placemarks:\n",
    "        desc = pm.find(\"kml:description\", ns)\n",
    "        coords_tag = pm.find(\".//kml:Point/kml:coordinates\", ns)\n",
    "\n",
    "        if desc is None or coords_tag is None or coords_tag.text is None:\n",
    "            continue\n",
    "\n",
    "        # description text\n",
    "        text = desc.text.replace(\"<br>\", \"\\n\")\n",
    "\n",
    "        def get(field):\n",
    "            m = re.search(fr\"{field}:\\s*([^\\n]+)\", text)\n",
    "            return m.group(1).strip() if m else None\n",
    "\n",
    "        # metadata from description\n",
    "        YearDay   = get(\"YearDay\")\n",
    "        Time      = get(\"Time\")\n",
    "        Satellite = get(\"Satellite\")\n",
    "        Method    = get(\"Method\")\n",
    "        Ecosystem = get(\"Ecosystem\")\n",
    "        FRP_raw   = get(\"FRP\")\n",
    "\n",
    "        # coordinates from <Point><coordinates>\n",
    "        try:\n",
    "            lon_str, lat_str, *_ = coords_tag.text.strip().split(\",\")\n",
    "            lon = float(lon_str)\n",
    "            lat = float(lat_str)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # clean FRP\n",
    "        FRP = None\n",
    "        if FRP_raw:\n",
    "            val = FRP_raw.replace(\"MW\", \"\").strip()\n",
    "            if val != \"-999.000\":\n",
    "                try:\n",
    "                    FRP = float(val)\n",
    "                except ValueError:\n",
    "                    FRP = None\n",
    "\n",
    "        rows.append({\n",
    "            \"lon\": lon,\n",
    "            \"lat\": lat,\n",
    "            \"YearDay\": YearDay,\n",
    "            \"Time\": Time,\n",
    "            \"Satellite\": Satellite,\n",
    "            \"Method\": Method,\n",
    "            \"Ecosystem\": Ecosystem,\n",
    "            \"FRP\": FRP\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # enforce numeric\n",
    "    df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "    df[\"YearDay\"] = pd.to_numeric(df[\"YearDay\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"lon\", \"lat\", \"YearDay\", \"Time\"])\n",
    "\n",
    "    # geometry column\n",
    "    geometry = [Point(xy) for xy in zip(df[\"lon\"], df[\"lat\"])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def add_timestamp_from_yearday_time(gdf):\n",
    "    \"\"\"\n",
    "    Add a 'timestamp' column combining YearDay (YYYYDDD) and Time (HHMMUTC)\n",
    "    \"\"\"\n",
    "    def _to_ts(row):\n",
    "        yd = int(row[\"YearDay\"])\n",
    "        t = str(row[\"Time\"])\n",
    "\n",
    "        # date from YearDay (YYYYDDD)\n",
    "        date = pd.to_datetime(str(yd), format=\"%Y%j\")\n",
    "\n",
    "        # time from HHMMUTC\n",
    "        t = t.replace(\"UTC\", \"\")\n",
    "        hh = int(t[:2])\n",
    "        mm = int(t[2:])\n",
    "        return date + pd.Timedelta(hours=hh, minutes=mm)\n",
    "\n",
    "    gdf = gdf.copy()\n",
    "    gdf[\"timestamp\"] = gdf.apply(_to_ts, axis=1)\n",
    "    return gdf\n",
    "\n",
    "def fire_pixels_to_episodes(gdf, round_decimals=3, max_gap_hours=2):\n",
    "    \"\"\"\n",
    "    From point detections (with 'lon', 'lat', 'timestamp'),\n",
    "    compute fire episodes per rounded pixel.\n",
    "    \"\"\"\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # ensure numeric\n",
    "    gdf[\"lon\"] = pd.to_numeric(gdf[\"lon\"], errors=\"coerce\")\n",
    "    gdf[\"lat\"] = pd.to_numeric(gdf[\"lat\"], errors=\"coerce\")\n",
    "    gdf = gdf.dropna(subset=[\"lon\", \"lat\", \"timestamp\"])\n",
    "\n",
    "    # round coordinates -> pixel grid\n",
    "    gdf[\"lon_round\"] = gdf[\"lon\"].round(round_decimals)\n",
    "    gdf[\"lat_round\"] = gdf[\"lat\"].round(round_decimals)\n",
    "\n",
    "    # pixel id\n",
    "    gdf[\"pixel_id\"] = (\n",
    "        gdf[\"lon_round\"].astype(str) + \"_\" + gdf[\"lat_round\"].astype(str)\n",
    "    )\n",
    "\n",
    "    # sort for episode grouping\n",
    "    gdf = gdf.sort_values([\"pixel_id\", \"timestamp\"])\n",
    "\n",
    "    # compute gaps in hours\n",
    "    gdf[\"prev_time\"] = gdf.groupby(\"pixel_id\")[\"timestamp\"].shift(1)\n",
    "    gdf[\"gap_hours\"] = (\n",
    "        gdf[\"timestamp\"] - gdf[\"prev_time\"]\n",
    "    ).dt.total_seconds() / 3600.0\n",
    "\n",
    "    # new episode when gap > threshold or no prev\n",
    "    gdf[\"new_episode\"] = gdf[\"gap_hours\"].isna() | (gdf[\"gap_hours\"] > max_gap_hours)\n",
    "\n",
    "    # cumulative sum per pixel gives episode id\n",
    "    gdf[\"episode_id\"] = gdf.groupby(\"pixel_id\")[\"new_episode\"].cumsum()\n",
    "\n",
    "    # aggregate episodes\n",
    "    episodes = (\n",
    "        gdf.groupby([\"pixel_id\", \"episode_id\"])\n",
    "        .agg(\n",
    "            lon=(\"lon_round\", \"first\"),\n",
    "            lat=(\"lat_round\", \"first\"),\n",
    "            start_time=(\"timestamp\", \"min\"),\n",
    "            end_time=(\"timestamp\", \"max\"),\n",
    "            detections=(\"timestamp\", \"count\"),\n",
    "            satellites=(\"Satellite\", lambda x: sorted(x.dropna().unique())),\n",
    "            max_frp=(\"FRP\", \"max\"),\n",
    "            mean_frp=(\"FRP\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    episodes[\"duration_hours\"] = (\n",
    "        episodes[\"end_time\"] - episodes[\"start_time\"]\n",
    "    ).dt.total_seconds() / 3600.0\n",
    "    episodes[\"duration_days\"] = episodes[\"duration_hours\"] / 24.0\n",
    "\n",
    "    # back to GeoDataFrame\n",
    "    episodes_gdf = gpd.GeoDataFrame(\n",
    "        episodes,\n",
    "        geometry=[Point(xy) for xy in zip(episodes[\"lon\"], episodes[\"lat\"])],\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    return episodes_gdf\n",
    "\n",
    "def process_fire_year_for_ca(kml_path, ca_polygon_gdf):\n",
    "    \"\"\"\n",
    "    Full pipeline for a single year:\n",
    "    - parse KML\n",
    "    - add timestamp\n",
    "    - filter to California only\n",
    "    - create episodes\n",
    "    \"\"\"\n",
    "    # 1. parse\n",
    "    gdf = parse_hms_fire_kml_to_geodf(kml_path)\n",
    "\n",
    "    # 2. add timestamp\n",
    "    gdf = add_timestamp_from_yearday_time(gdf)\n",
    "\n",
    "    # 3. filter to California via spatial join\n",
    "    gdf_ca = gpd.sjoin(\n",
    "        gdf,\n",
    "        ca_polygon_gdf[[\"geometry\"]],\n",
    "        how=\"inner\",\n",
    "        predicate=\"intersects\",\n",
    "    ).drop(columns=[\"index_right\"])\n",
    "\n",
    "    # 4. build episodes (CA only)\n",
    "    episodes_ca = fire_pixels_to_episodes(gdf_ca)\n",
    "\n",
    "    return episodes_ca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data/hms_fire2020.kml ...\n",
      "  → 482158 episodes in CA\n",
      "\n",
      "Processing data/hms_fire2021.kml ...\n",
      "  → 403359 episodes in CA\n",
      "\n",
      "Processing data/hms_fire2022.kml ...\n",
      "  → 57605 episodes in CA\n",
      "\n",
      "Processing data/hms_fire2023.kml ...\n",
      "  → 67568 episodes in CA\n",
      "\n",
      "Processing data/hms_fire2024.kml ...\n",
      "  → 120342 episodes in CA\n",
      "\n",
      "Processing data/hms_fire2025.kml ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/hms_fire2025.kml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m kml_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/hms_fire\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m.kml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mkml_file\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m episodes_ca \u001b[39m=\u001b[39m process_fire_year_for_ca(kml_file, ca)\n\u001b[1;32m      8\u001b[0m episodes_ca[\u001b[39m\"\u001b[39m\u001b[39myear\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m year\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  → \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(episodes_ca)\u001b[39m}\u001b[39;00m\u001b[39m episodes in CA\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 178\u001b[0m, in \u001b[0;36mprocess_fire_year_for_ca\u001b[0;34m(kml_path, ca_polygon_gdf)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39mFull pipeline for a single year:\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m- parse KML\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39m- create episodes\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# 1. parse\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m gdf \u001b[39m=\u001b[39m parse_hms_fire_kml_to_geodf(kml_path)\n\u001b[1;32m    180\u001b[0m \u001b[39m# 2. add timestamp\u001b[39;00m\n\u001b[1;32m    181\u001b[0m gdf \u001b[39m=\u001b[39m add_timestamp_from_yearday_time(gdf)\n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36mparse_hms_fire_kml_to_geodf\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mparse_hms_fire_kml_to_geodf\u001b[39m(filepath):\n\u001b[1;32m      9\u001b[0m     ns \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mkml\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhttp://www.opengis.net/kml/2.2\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m---> 10\u001b[0m     tree \u001b[39m=\u001b[39m ET\u001b[39m.\u001b[39;49mparse(filepath)\n\u001b[1;32m     11\u001b[0m     root \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mgetroot()\n\u001b[1;32m     13\u001b[0m     placemarks \u001b[39m=\u001b[39m root\u001b[39m.\u001b[39mfindall(\u001b[39m\"\u001b[39m\u001b[39m.//kml:Placemark\u001b[39m\u001b[39m\"\u001b[39m, ns)\n",
      "File \u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.10/xml/etree/ElementTree.py:1222\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \n\u001b[1;32m   1215\u001b[0m \u001b[39m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \n\u001b[1;32m   1220\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m tree \u001b[39m=\u001b[39m ElementTree()\n\u001b[0;32m-> 1222\u001b[0m tree\u001b[39m.\u001b[39;49mparse(source, parser)\n\u001b[1;32m   1223\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.10/xml/etree/ElementTree.py:569\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    567\u001b[0m close_source \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(source, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 569\u001b[0m     source \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(source, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    570\u001b[0m     close_source \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/hms_fire2025.kml'"
     ]
    }
   ],
   "source": [
    "all_years = []\n",
    "\n",
    "for year in range(2020, 2026):\n",
    "    kml_file = f\"data/hms_fire{year}.kml\"\n",
    "    print(f\"\\nProcessing {kml_file} ...\")\n",
    "\n",
    "    episodes_ca = process_fire_year_for_ca(kml_file, ca)\n",
    "    episodes_ca[\"year\"] = year\n",
    "\n",
    "    print(f\"  → {len(episodes_ca)} episodes in CA\")\n",
    "    all_years.append(episodes_ca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL SHAPE: (1131032, 14)\n"
     ]
    }
   ],
   "source": [
    "final_fire_episodes_ca = pd.concat(all_years, ignore_index=True)\n",
    "\n",
    "print(\"\\nFINAL SHAPE:\", final_fire_episodes_ca.shape)\n",
    "\n",
    "final_fire_episodes_ca[\"episode_key\"] = (\n",
    "    final_fire_episodes_ca[\"year\"].astype(str)\n",
    "    + \"_\"\n",
    "    + final_fire_episodes_ca[\"episode_id\"].astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fire_episodes_ca.to_parquet(\"data/fire_episodes_2020_2025.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
